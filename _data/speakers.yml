- abstract: Recently, there has been a surge of interest for object-centric learning
    in neural network research. To many researchers, it seems clear that objects hold
    great potential for enabling more systematic generalisation, building compositional
    models of the world, and as grounding for language and symbolic reasoning. However,
    despite strong intuitions, a general definition of what constitutes an object
    is still lacking, and the precise notion of objects remains largely elusive. In
    this talk I aim to challenge some common intuitive conceptions about objects,
    and point to some of their subtle complexity. After that, I will present a few
    relevant findings from cognitive psychology regarding human object perception,
    and conclude by discussing a few challenges and promising approaches for incorporating
    objects into neural networks.
  authors: Klaus Greff
  id: 34
  kind: oral
  slideslive_url: none
  title: What are Objects
  video_file_url: none
  youtube_id: none
- abstract: To enable explicit representation of objects in neural architectures,
    a core challenge lies in defining a mapping from input features (e.g., an image
    encoded by a CNN) to a set of abstract object representations. In this talk, I
    will discuss how attention mechanisms can be used in an iterative, competitive
    fashion to (a) efficiently group visual features into object slots and (b) segment
    temporal representations. I will further highlight how graph neural networks can
    be utilized to learn about interactions between objects and how object-centric
    models can be trained in a self-supervised fashion using contrastive losses.
  authors: Thomas Kipf
  id: 35
  kind: oral
  slideslive_url: none
  title: Attentive Grouping and Graph Neural Networks for Object-Centric Learning
  video_file_url: none
  youtube_id: none
- abstract: TBD
  authors: Fabien Baradel
  id: 36
  kind: oral
  slideslive_url: none
  title: Invited Talk 3
  video_file_url: none
  youtube_id: none
- abstract: Two-dimensional images are commonly used to study and model perceptual
    and cognitive processes because of the convenience and ease of experimental control
    they provide. However, real objects differ from pictures in many ways, including
    the potential for interaction and richer information about distance and thus size.
    Across a series of neuroimaging studies and behavioral experiments in adults,
    we have shown different responses to real objects than pictures. Moreover, we
    have found behavioral differences between real objects and pictures even in infants,
    suggesting that realness plays an important role in learning about objects. These
    results can inform the next generation of computational models as to how human
    brains learn to process objects in the real world.
  authors: Jody Culham
  id: 37
  kind: oral
  slideslive_url: none
  title: '"The treachery of images": How the realness of objects affects brain activation
    and behavior'
  video_file_url: none
  youtube_id: none
- abstract: TBD
  authors: Moira Dillon
  id: 38
  kind: oral
  slideslive_url: none
  title: Invited Talk 5
  video_file_url: none
  youtube_id: none
- abstract: TBD
  authors: Linda Smith
  id: 39
  kind: oral
  slideslive_url: none
  title: Invited Talk 6
  video_file_url: none
  youtube_id: none
- abstract: 'How we represent signals has major implications for the algorithms we
    build to analyze them. Today, most signals are represented discretely: Images
    as grids of pixels, shapes as point clouds, audio as grids of amplitudes, etc.
    If images weren''t pixel grids - would we be using convolutional neural networks
    today? What makes a good or bad representation? Can we do better? I will talk
    about leveraging emerging implicit neural representations for complex & large
    signals, such as room-scale geometry, images, audio, video, and physical signals
    defined via partial differential equations. By embedding an implicit scene representation
    in a neural rendering framework and learning a prior over these representations,
    I will show how we can enable 3D reconstruction from only a single posed 2D image.
    Finally, I will show how gradient-based meta-learning can enable fast inference
    of implicit representations, and how the features we learn in the process are
    already useful to the downstream task of semantic segmentation.'
  authors: Vincent Sitzmann
  id: 40
  kind: oral
  slideslive_url: none
  title: Implicit Neural Scene Representations
  video_file_url: none
  youtube_id: none
- abstract: TBD
  authors: Igor Mordatch
  id: 41
  kind: oral
  slideslive_url: none
  title: Invited Talk 7
  video_file_url: none
  youtube_id: none
